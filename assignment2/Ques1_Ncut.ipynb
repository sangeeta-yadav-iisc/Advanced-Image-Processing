{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "L-c1hAh-0shO"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-15798fb53df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrgb2hsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "eapujLL88RTb",
    "outputId": "95b6bbe0-0984-4145-aefa-d8fb63ed8f55"
   },
   "outputs": [],
   "source": [
    "image = imread(\"images/images/image1.jpg\")\n",
    "print(image.shape)\n",
    "plt.imshow(image)\n",
    "image = resize(image, (64, 64))\n",
    "hsv = rgb2hsv(image)\n",
    "\n",
    "hsv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueBRucnt0_QC"
   },
   "outputs": [],
   "source": [
    "def get_features(h, s, v):\n",
    "  return np.array([v, v * s * np.sin(h), v * s * np.cos(h)])\n",
    "\n",
    "def get_features_rgb(r, g, b):\n",
    "  return np.array([r,g,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkSRW22Q1N5w"
   },
   "outputs": [],
   "source": [
    "def get_feature_diff(feature_1, feature_2, sigma):\n",
    "  out = np.sum(np.square((feature_1 - feature_2)))/sigma\n",
    "  return out\n",
    "\n",
    "def get_difference_x(pt1, pt2, sigma):\n",
    "  dist = ((pt1[0] - pt2[0])**2 + (pt1[1] - pt2[1])**2 )\n",
    "  return dist/sigma, dist\n",
    "\n",
    "def get_difference_feature(pt1, pt2, feature_1, feature_2, r, sigmaI, sigmaX):\n",
    "  x_feat, dist = get_difference_x(pt1, pt2, sigmaX)\n",
    "\n",
    "  if dist > r:\n",
    "    return 0\n",
    "  else:\n",
    "    feature_diff = get_feature_diff(feature_1, feature_2, sigmaI)\n",
    "    result = np.exp(-x_feat) * np.exp(-feature_diff)\n",
    "  \n",
    "  return result\n",
    "\n",
    "def precompute_features(img):\n",
    "  feature_matrix = np.zeros(img.shape)\n",
    "\n",
    "  for i in range(0, img.shape[0]):\n",
    "    for j in range(0, img.shape[1]):\n",
    "      feature_matrix[i,j] = get_features(img[i,j,0], img[i,j,1], img[i,j,2])\n",
    "  \n",
    "  return feature_matrix\n",
    "\n",
    "def create_weight_matrix(img,r, sigmaI, sigmaX, mask = None):\n",
    "\n",
    "    feature_matrix = precompute_features(img)\n",
    "\n",
    "    weight_matrix = np.zeros((img.shape[0] * img.shape[1], img.shape[0] * img.shape[1]))\n",
    "    print(img.shape[0])\n",
    "    for i in range(img.shape[0]):\n",
    "      for j in range(img.shape[1]):\n",
    "        for k in range(img.shape[0]):\n",
    "          for l in range(img.shape[1]):\n",
    "            pt1 = [i, j]\n",
    "            pt2 = [k, l]\n",
    "            feature1 = feature_matrix[i,j]\n",
    "            feature2 = feature_matrix[k, l]\n",
    "            result = get_difference_feature(pt1, pt2, feature1, feature2, r, sigmaI, sigmaX)\n",
    "            if i == k and j == l:\n",
    "              result = 1\n",
    "            \n",
    "            weight_matrix[i * img.shape[0] + j, k * img.shape[0] + l] = result\n",
    "\n",
    "    return weight_matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kVhmG5um-qlv",
    "outputId": "c1438b9a-5cfa-4477-9264-f11ea7ee73d2"
   },
   "outputs": [],
   "source": [
    "precompute_features(hsv).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "Ic9xfs5s-usk",
    "outputId": "a2fbb340-15f2-4213-e8d4-dafb13134569"
   },
   "outputs": [],
   "source": [
    "%timeit\n",
    "weight_matrix = create_weight_matrix(hsv, 15, 0.1, 4)\n",
    "np.diag(weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "o6ZZOtuuU11l",
    "outputId": "40f0080f-d5d6-49f1-e6af-448154c2ff52"
   },
   "outputs": [],
   "source": [
    "def create_diag_matrix(weight_matrix):\n",
    "  y = np.zeros(weight_matrix.shape[0])\n",
    "\n",
    "  for i in range(weight_matrix.shape[0]):\n",
    "    y[i] = np.sum(weight_matrix[i,:])\n",
    "#     print(y[i])\n",
    "  diag_matrix = np.diag(y)\n",
    "  return diag_matrix\n",
    "\n",
    "diag_matrix = create_diag_matrix(weight_matrix)\n",
    "D = np.diag(1/np.sqrt(np.diag(diag_matrix)))\n",
    "final = D @ (diag_matrix - weight_matrix) @ D\n",
    "u, v = np.linalg.eigh(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "PGTakD7m42q_",
    "outputId": "75d631a0-7e0a-4a96-b6eb-47efada1a072"
   },
   "outputs": [],
   "source": [
    "seg_map = np.copy(v[:,1].reshape((64,64)))\n",
    "minimum = np.min(seg_map)\n",
    "maximum = np.max(seg_map)\n",
    "seg_map = (seg_map - minimum)/(maximum - minimum)\n",
    "plt.imshow(seg_map, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymAk0lv-4-aK"
   },
   "outputs": [],
   "source": [
    "seg_map = v[:,3].reshape((64,64))\n",
    "def view_segmap(seg_map):\n",
    "  minimum = np.min(seg_map)\n",
    "  maximum = np.max(seg_map)\n",
    "  seg_map = (seg_map - minimum)/(maximum - minimum)\n",
    "  plt.imshow(seg_map, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "i7U6G2mQBozl",
    "outputId": "f2534e91-294c-44a2-f405-ac86e85dd630"
   },
   "outputs": [],
   "source": [
    "seg_map = np.copy(v[:,2].reshape((64,64)))\n",
    "\n",
    "minimum = np.min(seg_map)\n",
    "maximum = np.max(seg_map)\n",
    "\n",
    "seg_map = (seg_map - minimum)/(maximum - minimum)\n",
    "median = np.median(seg_map)\n",
    "print(median)\n",
    "final_map = seg_map > median\n",
    "plt.imshow(final_map, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "Pep7v4rbkpkw",
    "outputId": "8b578804-9f88-4039-8b29-b0959b050fc2"
   },
   "outputs": [],
   "source": [
    "seg_map = v[:,2].reshape((64,64)) * final_map\n",
    "\n",
    "minimum = np.min(seg_map)\n",
    "maximum = np.max(seg_map)\n",
    "\n",
    "seg_map = (seg_map - minimum)/(maximum - minimum)\n",
    "median = np.median(seg_map)\n",
    "final_map2 = seg_map > median\n",
    "plt.imshow(final_map2, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "nrPszQLwpHAj",
    "outputId": "9574b49a-b05b-46d0-eae3-88ce81c44325"
   },
   "outputs": [],
   "source": [
    "seg_map = v[:,2].reshape((64,64)) * (1 - final_map)\n",
    "\n",
    "minimum = np.min(seg_map)\n",
    "maximum = np.max(seg_map)\n",
    "\n",
    "seg_map = (seg_map - minimum)/(maximum - minimum)\n",
    "median = np.median(seg_map)\n",
    "final_map3 = seg_map > median\n",
    "plt.imshow(final_map3, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "DSo8c45oprLj",
    "outputId": "df9919d9-3823-4626-eeb6-3c64383d3106"
   },
   "outputs": [],
   "source": [
    "seg_map = v[:,3].reshape((64,64)) * final_map2 * final_map\n",
    "\n",
    "minimum = np.min(seg_map)\n",
    "maximum = np.max(seg_map)\n",
    "\n",
    "seg_map = (seg_map - minimum)/(maximum - minimum)\n",
    "median = np.median(seg_map)\n",
    "final_map4 = seg_map > median\n",
    "plt.imshow(final_map4, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "YWHaaAazqIi6",
    "outputId": "2d4dd27f-e9ca-4247-e7d7-02b18efd9ca9"
   },
   "outputs": [],
   "source": [
    "seg_map = v[:,3].reshape((64,64)) * (1 - final_map2) * final_map\n",
    "\n",
    "minimum = np.min(seg_map)\n",
    "maximum = np.max(seg_map)\n",
    "\n",
    "seg_map = (seg_map - minimum)/(maximum - minimum)\n",
    "median = np.median(seg_map)\n",
    "final_map5 = seg_map > median\n",
    "plt.imshow(final_map5, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "VMROxmuBqR2r",
    "outputId": "872eb850-09c6-4db8-d74e-656e600df4c4"
   },
   "outputs": [],
   "source": [
    "seg_map = v[:,4].reshape((64,64))* final_map5* (1 - final_map2) * final_map\n",
    "\n",
    "minimum = np.min(seg_map)\n",
    "maximum = np.max(seg_map)\n",
    "\n",
    "seg_map = (seg_map - minimum)/(maximum - minimum)\n",
    "median = np.median(seg_map)\n",
    "final_map6 = seg_map > median\n",
    "plt.imshow(final_map6, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "ACe2lcd4rKxE",
    "outputId": "86bde55f-d40b-418a-efc0-3d0eb5c9f0a3"
   },
   "outputs": [],
   "source": [
    "seg_map = v[:,4].reshape((64,64))* (1-final_map5)* (1 - final_map2) * final_map\n",
    "\n",
    "minimum = np.min(seg_map)\n",
    "maximum = np.max(seg_map)\n",
    "\n",
    "seg_map = (seg_map - minimum)/(maximum - minimum)\n",
    "median = np.median(seg_map)\n",
    "final_map7 = seg_map > median\n",
    "plt.imshow(final_map7, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USM6ztDtrWiK"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from numpy import array, reshape, shape, matrix, ones, zeros, sqrt, sort, arange\n",
    "from numpy import nonzero, fromfile, tile, append, prod, double, argsort, sign\n",
    "from numpy import kron, multiply, divide, abs, reshape, asarray\n",
    "from scipy import rand\n",
    "from scipy.sparse import csc_matrix, spdiags\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "from scipy.linalg import norm, svd, LinAlgError\n",
    "\n",
    "# exception hander for singular value decomposition\n",
    "class SVDError(Exception):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return repr(self.value)\n",
    "\n",
    "\n",
    "def ncut(W, nbEigenValues):\n",
    "    # parameters\n",
    "    offset = .5\n",
    "    maxiterations = 100\n",
    "    eigsErrorTolerence = 1e-6\n",
    "    truncMin = 1e-6\n",
    "    eps = 2.2204e-16\n",
    "\n",
    "    m = shape(W)[1]\n",
    "\n",
    "    \n",
    "    d = abs(W).sum(0)\n",
    "    dr = 0.5 * (d - W.sum(0))\n",
    "    d = d + offset * 2\n",
    "    dr = dr + offset\n",
    "\n",
    "    # calculation of the normalized LaPlacian\n",
    "    W = W + spdiags(dr, [0], m, m, \"csc\")\n",
    "    Dinvsqrt = spdiags((1.0 / sqrt(d + eps)), [0], m, m, \"csc\")\n",
    "    P = Dinvsqrt * (W * Dinvsqrt);\n",
    "\n",
    "    # perform the eigen decomposition\n",
    "    #eigen_val, eigen_vec = eigsh(P, nbEigenValues, maxiter=maxiterations, tol=eigsErrorTolerence, which='LA')\n",
    "    eigen_val, eigen_vec = eigsh(P, nbEigenValues, tol=eigsErrorTolerence, which='LA')\n",
    "\n",
    "    # sort the eigen_vals so that the first\n",
    "    # is the largest\n",
    "    i = argsort(-eigen_val)\n",
    "    eigen_val = eigen_val[i]\n",
    "    eigen_vec = eigen_vec[:, i]\n",
    "\n",
    "    # normalize the returned eigenvectors\n",
    "    eigen_vec = Dinvsqrt * matrix(eigen_vec)\n",
    "    norm_ones = norm(ones((m, 1)))\n",
    "    for i in range(0, shape(eigen_vec)[1]):\n",
    "        eigen_vec[:, i] = (eigen_vec[:, i] / norm(eigen_vec[:, i])) * norm_ones\n",
    "        if eigen_vec[0, i] != 0:\n",
    "            eigen_vec[:, i] = -1 * eigen_vec[:, i] * sign(eigen_vec[0, i])\n",
    "\n",
    "    return (eigen_val, eigen_vec)\n",
    "\n",
    "\n",
    "# eigenvec_discrete=discretisation( eigen_vec ):\n",
    "#\n",
    "# This function performs the second step of normalized cut clustering which assigns features to clusters \n",
    "# based on the eigen vectors from the LaPlacian of a similarity matrix. There are a few different ways to\n",
    "# perform this task. Shi and Malik (2000) iteratively bisect the features based on the positive and \n",
    "# negative loadings of the eigenvectors. Ng, Jordan and Weiss (2001) proposed to perform K-means clustering\n",
    "# on the rows of the eigenvectors. The method implemented here was proposed by Yu and Shi (2003) and it finds\n",
    "# a discrete solution by iteratively rotating a binaised set of vectors until they are maximally similar to\n",
    "# the the eigenvectors (for more information, the full citation is at the top of this file). An advantage\n",
    "# of this method over K-means is that it is _more_ deterministic, i.e. you should get very similar results\n",
    "# every time you run the algorithm on the same data.\n",
    "#\n",
    "# The number of clusters that the features are clustered into is determined by the number of eignevectors \n",
    "# (number of columns) in the input array eigen_vec. A caveat of this method, is that number of resulting\n",
    "# clusters is bound by the number of eignevectors, but it may contain less.\n",
    "#\n",
    "#    eigen_vec:          Eigenvectors of the normalized LaPlacian calculated from the similarity matrix \n",
    "#                        for the corresponding clustering problem\n",
    "#    eigen_vec_discrete: (output) discretised eigenvectors, i.e. vectors of 0 and 1 which indicate \n",
    "#                        wether or not a feature belongs to the cluster defined by the eigen vector.\n",
    "#                        I.E. a one in the 10th row of the 4th eigenvector (column) means that feature\n",
    "#                        10 belongs to cluster #4.\n",
    "# \n",
    "def discretisation(eigen_vec):\n",
    "    eps = 2.2204e-16\n",
    "\n",
    "    # normalize the eigenvectors\n",
    "    [n, k] = shape(eigen_vec)\n",
    "    vm = np.linalg.norm(eigen_vec, axis=0, keepdims = True)\n",
    "    eigen_vec = divide(eigen_vec, vm)\n",
    "\n",
    "    svd_restarts = 0\n",
    "    exitLoop = 0\n",
    "\n",
    "    ### if there is an exception we try to randomize and rerun SVD again\n",
    "    ### do this 30 times\n",
    "    while (svd_restarts < 30) and (exitLoop == 0):\n",
    "\n",
    "        # initialize algorithm with a random ordering of eigenvectors\n",
    "        c = zeros((n, 1))\n",
    "        R = matrix(zeros((k, k)))\n",
    "        print(R[:, 0].shape)\n",
    "        R[:, 0] = eigen_vec[int(rand(1) * (n)), :].transpose()[:, np.newaxis]\n",
    "\n",
    "        for j in range(1, k):\n",
    "            c = c + abs(eigen_vec * R[:, j - 1])\n",
    "            R[:, j] = eigen_vec[c.argmin(), :].transpose()[:, np.newaxis]\n",
    "\n",
    "        lastObjectiveValue = 0\n",
    "        nbIterationsDiscretisation = 0\n",
    "        nbIterationsDiscretisationMax = 20\n",
    "\n",
    "        # iteratively rotate the discretised eigenvectors until they\n",
    "        # are maximally similar to the input eignevectors, this\n",
    "        # converges when the differences between the current solution\n",
    "        # and the previous solution differs by less than eps or we\n",
    "        # we have reached the maximum number of itarations\n",
    "        while exitLoop == 0:\n",
    "            nbIterationsDiscretisation = nbIterationsDiscretisation + 1\n",
    "\n",
    "            # rotate the original eigen_vectors\n",
    "            tDiscrete = eigen_vec * R\n",
    "\n",
    "            # discretise the result by setting the max of each row=1 and\n",
    "            # other values to 0\n",
    "            j = reshape(asarray(tDiscrete.argmax(1)), n)\n",
    "            eigenvec_discrete = csc_matrix((ones(len(j)), (range(0, n), array(j))), shape=(n, k))\n",
    "\n",
    "            # calculate a rotation to bring the discrete eigenvectors cluster to the\n",
    "            # original eigenvectors\n",
    "            tSVD = eigenvec_discrete.transpose() * eigen_vec\n",
    "            # catch a SVD convergence error and restart\n",
    "            try:\n",
    "                U, S, Vh = svd(tSVD)\n",
    "                svd_restarts += 1\n",
    "            except LinAlgError:\n",
    "                # catch exception and go back to the beginning of the loop\n",
    "                print >> sys.stderr, \"SVD did not converge, randomizing and trying again\"\n",
    "                break\n",
    "\n",
    "            # test for convergence\n",
    "            NcutValue = 2 * (n - S.sum())\n",
    "            if ((abs(NcutValue - lastObjectiveValue) < eps ) or\n",
    "                    ( nbIterationsDiscretisation > nbIterationsDiscretisationMax )):\n",
    "                exitLoop = 1\n",
    "            else:\n",
    "                # otherwise calculate rotation and continue\n",
    "                lastObjectiveValue = NcutValue\n",
    "                R = matrix(Vh).transpose() * matrix(U).transpose()\n",
    "\n",
    "    if exitLoop == 0:\n",
    "        raise SVDError(\"SVD did not converge after 30 retries\")\n",
    "    else:\n",
    "        return (eigenvec_discrete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "aQsKHykmOmAc",
    "outputId": "6468e497-8687-4d5e-fc39-dd238ee95dc8"
   },
   "outputs": [],
   "source": [
    "disc = discretisation(v[:,1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "WmWfc-GmVRaH",
    "outputId": "6760ce6c-faf8-4f82-a989-7c4c1d78af7d"
   },
   "outputs": [],
   "source": [
    "view_segmap(disc[:,0].todense().reshape((64,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "V3464X3RV5ns",
    "outputId": "e6331da8-cfc4-40f5-c428-9cf69b7064e9"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import pairwise_distances_argmin\n",
    "# from sklearn.datasets import load_sample_image\n",
    "# from sklearn.utils import shuffle\n",
    "# from time import time\n",
    "\n",
    "# n_colors = 3\n",
    "\n",
    "# # Load the Summer Palace photo\n",
    "# china = np.copy(v[:,1].reshape((64,64)))\n",
    "\n",
    "# # Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# # 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# # be in the range [0-1])\n",
    "# china = np.array(china, dtype=np.float64) \n",
    "\n",
    "# # Load Image and transform to a 2D numpy array.\n",
    "# w, h = original_shape = tuple(china.shape)\n",
    "# d = 1\n",
    "# assert d == 1\n",
    "# image_array = np.reshape(china, (w * h, d))\n",
    "\n",
    "# print(\"Fitting model on a small sub-sample of the data\")\n",
    "# t0 = time()\n",
    "# image_array_sample = shuffle(image_array, random_state=0)[:1000]\n",
    "# kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "# print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# # Get labels for all points\n",
    "# print(\"Predicting color indices on the full image (k-means)\")\n",
    "# t0 = time()\n",
    "# labels = kmeans.predict(image_array)\n",
    "# print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "\n",
    "# codebook_random = shuffle(image_array, random_state=0)[:n_colors]\n",
    "# print(\"Predicting color indices on the full image (random)\")\n",
    "# t0 = time()\n",
    "# labels_random = pairwise_distances_argmin(codebook_random,\n",
    "#                                           image_array,\n",
    "#                                           axis=0)\n",
    "# print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "\n",
    "# def recreate_image(codebook, labels, w, h):\n",
    "#     \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "#     d = codebook.shape[1]\n",
    "#     image = np.zeros((w, h, d))\n",
    "#     label_idx = 0\n",
    "#     for i in range(w):\n",
    "#         for j in range(h):\n",
    "#             image[i][j] = codebook[labels[label_idx]]\n",
    "#             label_idx += 1\n",
    "#     return image\n",
    "\n",
    "# # Display all results, alongside original image\n",
    "# plt.figure(1)\n",
    "# plt.clf()\n",
    "# plt.axis('off')\n",
    "# plt.title('Original image (96,615 colors)')\n",
    "# plt.imshow(china)\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.clf()\n",
    "# plt.axis('off')\n",
    "# plt.title('Quantized image (64 colors, K-Means)')\n",
    "# plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h).reshape((64,64)))\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.clf()\n",
    "# plt.axis('off')\n",
    "# plt.title('Quantized image (64 colors, Random)')\n",
    "# plt.imshow(recreate_image(codebook_random, labels_random, w, h).reshape((64,64)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "VrQKlK023n0c",
    "outputId": "f2820d6e-106f-44f8-ee86-ce8ed0cacab9"
   },
   "outputs": [],
   "source": [
    "# from skimage import data, segmentation, color\n",
    "# from skimage.future import graph\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# img = data.coffee()\n",
    "\n",
    "# labels1 = segmentation.slic(image, compactness=30, n_segments=3)\n",
    "# out1 = color.label2rgb(labels1, image, kind='avg', bg_label=0)\n",
    "\n",
    "# g = graph.rag_mean_color(hsv, labels1, mode='similarity')\n",
    "# labels2 = graph.cut_normalized(labels1, g)\n",
    "# out2 = color.label2rgb(labels2, image, kind='avg', bg_label=0)\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True, figsize=(6, 8))\n",
    "\n",
    "# ax[0].imshow(out1)\n",
    "# ax[1].imshow(out2)\n",
    "\n",
    "# for a in ax:\n",
    "#     a.axis('off')\n",
    "\n",
    "# plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
